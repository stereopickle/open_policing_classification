{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "In this notebook, I'll look at the data and deal with missing values. Also excluding dataset with data quality deemed suspicious based on the original document (https://github.com/stanford-policylab/opp/blob/master/data_readme.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "pd.options.display.max_seq_items = None\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('DATA/full_df.csv', index_col = 0, dtype = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case columns to make it searchable\n",
    "df0.columns = [x.lower() for x in df0.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data\n",
    "Raw data are original data. I'll separate these out since we may not need to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW = df0[df0.columns[df0.columns.str.startswith('raw')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df0.drop(RAW[1:], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values & Subsetting Data\n",
    "There are many missing values. I'll use outcome as a target variable and drop missing outcome (should not infer target variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103262"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.outcome.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "citation    193921\n",
       "warning      96064\n",
       "arrest       10431\n",
       "summons       2580\n",
       "Name: outcome, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['outcome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columnns are just breakdown of outcome. I'll remove those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['citation_issued', 'warning_issued', 'arrest_made'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns are post-outcome occurrences, I'll remove those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['reason_for_arrest'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hardfort, CT dataset was considered 'suspicious' by others who have made the cleaned individual dataset from raw data. I'll remove those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.fname != 'ct_hartford_2020_04_01.csv',:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove a column if it's missing majority of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[df.isnull().sum() > (len(df)/2)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the entire location if the location misses majority of race and sex information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.groupby('fname').agg({\n",
    "                        'subject_race': lambda x: x.isnull().sum()/len(x), \n",
    "                        'subject_sex': lambda x: x.isnull().sum()/len(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = list(tmp[(tmp.subject_race > 0.5) | (tmp.subject_sex > 0.5)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.fname.isin(to_remove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all info with missing race and sex information (key predictor without means to infer value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['subject_race', 'subject_sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this analysis, I'll drop rows if subject age and violation is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['subject_age', 'violation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing time with average hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill time with average hour\n",
    "hour = str(int(df.time.dropna().apply(lambda x: int(x[:2])).mean()))\n",
    "df.time = df.time.fillna(f'{hour}:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get city/state from fname and remove location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state'] = [x.split('_')[0] for x in df.fname]\n",
    "df['city'] = [x[:-15][3:] for x in df.fname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('location', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('fname', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For missing lat/long, impute the general location from the city info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "def get_lat_long(location):\n",
    "    geolocator = Nominatim(user_agent = \"open_polici_dat\")\n",
    "    location = geolocator.geocode(location)\n",
    "    return (location.latitude, location.longitude)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'] = np.where(df['city'] == 'statewide', df['state'], df['city'] + ', ' + df['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: oklahoma_city, ok\n"
     ]
    }
   ],
   "source": [
    "locations = set(df.location)\n",
    "all_loc = dict.fromkeys(locations, ())\n",
    "\n",
    "for loc in locations:\n",
    "    try:\n",
    "        all_loc[loc] = get_lat_long(loc)\n",
    "    except AttributeError:\n",
    "        print(f'error: {loc}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loc['oklahoma_city, ok'] = get_lat_long('Oklahoma City, OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lat'] = df.location.apply(lambda x: all_loc[x][0])\n",
    "df['lng'] = df.location.apply(lambda x: all_loc[x][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For search conducted, I'll add unknown as category for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.search_conducted = df.search_conducted.fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For types, if I find vehicular related words from violation I'll put vehicular, otherwise I'll put 'others'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['violation'] = df.violation.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehic_list_ = ['veh', 'ticket', 'traf', 'dmv', 'belt', 'speed', 'stop sign', 'dui', \n",
    "         'registration', 'parking', 'driv', 'yield', 'insurance', 'right of way', 'oper', 'fast',\n",
    "              'bicycle', 'phone', 'lane', 'helmet', 'oneway', 'lighting', 'stop/stand', 'reg', 'backing',\n",
    "               'highway', 'light', 'over height', 'freeway', 'license', 'hydrant', 'turn', 'safety chain']\n",
    "df['vehicular_indicator'] = df.violation.apply(lambda x: any(vehic_list_ in x for vehic_list_ in vehic_list_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'] = np.where((df.type.isnull()) & (df.vehicular_indicator), 'vehicular', df.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "ped_list = ['pedest', 'public', 'in park', 'walk', 'larceny', 'tresp', 'shoplift', 'curfew',\n",
    "            'gathering', 'disorderly conduct', 'street', 'closed park', 'touching', 'theft', 'outdoors']\n",
    "df['pedestrian_indicator'] = df.violation.apply(lambda x: any(ped_list in x for ped_list in ped_list))\n",
    "df['type'] = np.where((df.type.isnull()) & (df.pedestrian_indicator), 'pedestrian', df.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.type = df['type'].fillna('others')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export\n",
    "Exporting the cleaned dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_pickle('PKL/clean_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
