{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "Data collected from Standford's Open Policing database.  \n",
    "(https://openpolicing.stanford.edu/data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting file links\n",
    "I'll first scrape all csv zip file urls from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_page = requests.get('https://openpolicing.stanford.edu/data/')\n",
    "soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "file_urls = soup.findAll('a', title = 'Download data as CSV')\n",
    "links = [link.get('href') for link in file_urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and compile\n",
    "I'll iterate through each zip file, download, unzip, open csv and filter only data from 2015 (to keep the data at manageable size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar_little_rock_2020_04_01.csv Completed\n",
      "az_gilbert_2020_04_01.csv Completed\n",
      "az_mesa_2020_04_01.csv Completed\n",
      "az_statewide_2020_04_01.csv Completed\n",
      "ca_anaheim_2020_04_01.csv Completed\n",
      "ca_bakersfield_2020_04_01.csv Completed\n",
      "ca_long_beach_2020_04_01.csv Completed\n",
      "ca_los_angeles_2020_04_01.csv Completed\n",
      "ca_oakland_2020_04_01.csv Completed\n",
      "ca_san_bernardino_2020_04_01.csv Completed\n",
      "ca_san_diego_2020_04_01.csv Completed\n",
      "ca_san_francisco_2020_04_01.csv Completed\n",
      "ca_san_jose_2020_04_01.csv Completed\n",
      "ca_santa_ana_2020_04_01.csv Completed\n",
      "ca_statewide_2020_04_01.csv Completed\n",
      "ca_stockton_2020_04_01.csv Completed\n",
      "co_aurora_2020_04_01.csv Completed\n",
      "co_denver_2020_04_01.csv Completed\n",
      "co_statewide_2020_04_01.csv Completed\n",
      "ct_hartford_2020_04_01.csv Completed\n",
      "ct_statewide_2020_04_01.csv Completed\n",
      "fl_saint_petersburg_2020_04_01.csv Completed\n",
      "fl_statewide_2020_04_01.csv Completed\n",
      "fl_tampa_2020_04_01.csv Completed\n",
      "ga_statewide_2020_04_01.csv Completed\n",
      "ia_statewide_2020_04_01.csv Completed\n",
      "id_idaho_falls_2020_04_01.csv Completed\n",
      "il_chicago_2020_04_01.csv Completed\n",
      "il_statewide_2020_04_01.csv Completed\n",
      "in_fort_wayne_2020_04_01.csv Completed\n",
      "ks_wichita_2020_04_01.csv Completed\n",
      "ky_louisville_2020_04_01.csv Completed\n",
      "ky_owensboro_2020_04_01.csv Completed\n",
      "la_new_orleans_2020_04_01.csv Completed\n",
      "ma_statewide_2020_04_01.csv Completed\n",
      "md_baltimore_2020_04_01.csv Completed\n",
      "md_statewide_2020_04_01.csv Completed\n",
      "mi_statewide_2020_04_01.csv Completed\n",
      "mn_saint_paul_2020_04_01.csv Completed\n",
      "mo_statewide_2020_04_01.csv Completed\n",
      "ms_statewide_2020_04_01.csv Completed\n",
      "mt_statewide_2020_04_01.csv Completed\n",
      "nc_charlotte_2020_04_01.csv Completed\n",
      "nc_durham_2020_04_01.csv Completed\n",
      "nc_fayetteville_2020_04_01.csv Completed\n",
      "nc_greensboro_2020_04_01.csv Completed\n",
      "nc_raleigh_2020_04_01.csv Completed\n",
      "nc_statewide_2020_04_01.csv Completed\n",
      "nc_winston-salem_2020_04_01.csv Completed\n",
      "nd_grand_forks_2020_04_01.csv Completed\n",
      "nd_statewide_2020_04_01.csv Completed\n",
      "ne_statewide_2020_04_01.csv Completed\n",
      "nh_statewide_2020_04_01.csv Completed\n",
      "nj_camden_2020_04_01.csv Completed\n",
      "nj_statewide_2020_04_01.csv Completed\n",
      "nv_henderson_2020_04_01.csv Completed\n",
      "nv_statewide_2020_04_01.csv Completed\n",
      "ny_albany_2020_04_01.csv Completed\n",
      "ny_statewide_2020_04_01.csv Completed\n",
      "oh_cincinnati_2020_04_01.csv Completed\n",
      "oh_columbus_2020_04_01.csv Completed\n",
      "oh_statewide_2020_04_01.csv Completed\n",
      "ok_oklahoma_city_2020_04_01.csv Completed\n",
      "ok_tulsa_2020_04_01.csv Completed\n",
      "or_statewide_2020_04_01.csv Completed\n",
      "pa_philadelphia_2020_04_01.csv Completed\n",
      "pa_pittsburgh_2020_04_01.csv Completed\n",
      "ri_statewide_2020_04_01.csv Completed\n",
      "sc_statewide_2020_04_01.csv Completed\n",
      "sd_statewide_2020_04_01.csv Completed\n",
      "tn_nashville_2020_04_01.csv Completed\n",
      "tn_statewide_2020_04_01.csv Completed\n",
      "tx_arlington_2020_04_01.csv Completed\n",
      "tx_austin_2020_04_01.csv Completed\n",
      "tx_garland_2020_04_01.csv Completed\n",
      "tx_houston_2020_04_01.csv Completed\n",
      "tx_lubbock_2020_04_01.csv Completed\n",
      "tx_plano_2020_04_01.csv Completed\n",
      "tx_san_antonio_2020_04_01.csv Completed\n",
      "tx_statewide_2020_04_01.csv Completed\n",
      "va_statewide_2020_04_01.csv Completed\n",
      "vt_burlington_2020_04_01.csv Completed\n",
      "vt_statewide_2020_04_01.csv Completed\n",
      "wa_seattle_2020_04_01.csv Completed\n",
      "wa_statewide_2020_04_01.csv Completed\n",
      "wa_tacoma_2020_04_01.csv Completed\n",
      "wi_madison_2020_04_01.csv Completed\n",
      "wi_statewide_2020_04_01.csv Completed\n",
      "wy_statewide_2020_04_01.csv Completed\n"
     ]
    }
   ],
   "source": [
    "full_df = pd.DataFrame()\n",
    "\n",
    "for link in links:\n",
    "    # open url\n",
    "    resp = urlopen(link)\n",
    "    # read zipfile\n",
    "    zipfile = ZipFile(BytesIO(resp.read()))\n",
    "    # get the csv file name\n",
    "    fname = zipfile.namelist()[0]\n",
    "    # convert to pandas dateframe\n",
    "    df = pd.read_csv(zipfile.open(fname), dtype=object)\n",
    "    # close file\n",
    "    zipfile.close()\n",
    "    # convert date string to datetime object\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    # filter dataframe\n",
    "    df = df[(df.date > '2015-01-01') & (df.date < '2016-01-01')]\n",
    "    # then only sample 5000\n",
    "    if len(df) >= 5000:\n",
    "        df = df.sample(5000)\n",
    "    # add fname to use later to grab location info\n",
    "    df['fname'] = fname\n",
    "    # concat\n",
    "    full_df = pd.concat([full_df, df], ignore_index=True, sort=False)\n",
    "    # let me know where you are\n",
    "    print(f'{fname} Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_df.to_csv('DATA/full_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
